{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smiley Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emot.core import emot\n",
    "from googletrans import Translator  # version 3.1.0a0 use: pip install googletrans==3.1.0a0\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get the right english translation \n",
    "from the 'mean' value in the dictionary returned by the <code>emoticon()</code> function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. '^[^\\s,]+,': match the first word before the first comma\n",
    "    - ^:        start of the string\n",
    "    - [^\\s,]+:  match any character that is not a space or a comma, one or more times\n",
    "\n",
    "2. '^[^,]+,\\s*(\\w+)': match the first word after the first comma if there are multiple words before the comma\n",
    "    - ^:        start of the string\n",
    "    - [^,]+:    one or more characters that are not commas, followed by a comma\n",
    "    - \\s*:      zero or more whitespace characters (e.g., spaces or tabs)\n",
    "    - (\\w+):    one or more word characters (e.g., letters, digits, or underscores), captured in a group\n",
    "    \n",
    "3. '^\\s*([\\w\\s]+?)\\s*or\\b': match the first words before the word 'or'\n",
    "    - ^:            start of the string\n",
    "    - \\s*:          zero or more whitespace characters (e.g., spaces or tabs)\n",
    "    - ([\\w\\s]+?):   one or more word characters (e.g., letters, digits, or underscores), or whitespace characters, captured in a non-greedy group\n",
    "    - \\s*:          zero or more whitespace characters\n",
    "    - or\\b:         the word \"or\", followed by a word boundary (to avoid matching words like \"order\" or \"orange\")\n",
    "'''\n",
    "def replacer(meanings):\n",
    "    regex = re.compile(r'^[^\\s,]+,')\n",
    "    match = regex.match(meanings)\n",
    "    if match:\n",
    "        return match.group(0)[:-1]\n",
    "    \n",
    "    regex = re.compile(r'^[^,]+,\\s*(\\w+)')\n",
    "    match = regex.match(meanings)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    regex = re.compile(r'^\\s*([\\w\\s]+?)\\s*or\\b')\n",
    "    match = regex.match(meanings)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    return meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hoi Andre i bi nöd bös Skeptisch, lachend, frech, glückliches Gesicht, Stirnrunzeln, sehr glückliches Gesicht, sehr sehr glückliches Gesicht, glückliches Gesicht Smiley'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_emoticons(text):\n",
    "    emotions = emot().emoticons(text)\n",
    "    translator = Translator()\n",
    "    correction = 0\n",
    "    for i, location in enumerate(emotions['location']):\n",
    "        emoticon = emotions['value'][i]\n",
    "        start = location[0] + correction\n",
    "        end = location[1] + correction\n",
    "        meaning = emotions['mean'][i]\n",
    "        replacement = replacer(meaning)\n",
    "        text = text[:start] + replacement + text[end:]\n",
    "        correction += len(replacement) - len(emoticon)     # correction for the length of the emoticon\n",
    "    return translator.translate(translator.translate(text, dest='en').text, dest='de').text\n",
    "test = \"Hoi Andre i bi nöd bös :/, :D, :P, :), :(, :)), :))), :-)\"\n",
    "translate_emoticons(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translate swiss german to standard german"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to install googletrans version 3.1.0a0\n",
    "def translate_swiss_german(text):\n",
    "    translator = Translator()\n",
    "    return translator.translate(translator.translate(text, src='de', dest='en').text, src='en', dest='de').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texte = ['Das isch en super Sach!', \n",
    "         'I lieb di au!', \n",
    "         \"Chrischtbaumschmuck, Brunsli, Nusshüüfeli, Haferflockeguetzli, Zimetstärn hani gärn, Mailänderli au, Aenisguetzli, Chrischtchindli, es lüütet es Glöögli, Schtilli Nacht, Schternschnuppe,s' Jesuschindli liit i de Chrippe, äs isch zu euch Mänsche uf d'Aerde abe cho\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das isch en super Sach!\n",
      "Das ist eine tolle Sache!\n",
      "\n",
      "I lieb di au!\n",
      "Ich liebe dich jetzt!\n",
      "\n",
      "Chrischtbaumschmuck, Brunsli, Nusshüüfeli, Haferflockeguetzli, Zimetstärn hani gärn, Mailänderli au, Aenisguetzli, Chrischtchindli, es lüütet es Glöögli, Schtilli Nacht, Schternschnuppe,s' Jesuschindli liit i de Chrippe, äs isch zu euch Mänsche uf d'Aerde abe cho\n",
      "Christbaumschmuck, Brunsli, Nusshüüfeli, Haferflockenkekse, Zimtstangen Hani Gärn, Mailänderli au, Aenisguetzli, Chrischtchindli, es lüütet Glöögli, Schtilli Nacht, Schternschnuppe, s'Jesuschindli liit i de Chrippe, es ist euch Leuten auf d'Aerde aber cho\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texte:\n",
    "    print(text)\n",
    "    print(translate_swiss_german(text))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time the function with multiple Emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15 s ± 172 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 5 -n 10 translate_emoticons(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 ms ± 11.2 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 5 -n 10 translate_swiss_german(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACEBOOK_PATH = \"facebook_dataset/translated.csv\"\n",
    "SENTIMENT_PATH = \"dataset/sentiment.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56945, 7) (2799, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>md5_hash</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>un</th>\n",
       "      <th>unsure</th>\n",
       "      <th>neut</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101180699934084_27535</td>\n",
       "      <td>92886373210_101180699934084</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>38540bcfd66b046240b62b9e3482442c</td>\n",
       "      <td>61217</td>\n",
       "      <td>ghana und serbien: smiley mit fröhlichem gesicht</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101180699934084_28236</td>\n",
       "      <td>92886373210_101180699934084</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3fee57e44994d5f406f797e2e9819c13</td>\n",
       "      <td>30919</td>\n",
       "      <td>wer sonst?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10150099003948783_14797768</td>\n",
       "      <td>92886373210_10150099003948783</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>58dc5fa1f3b24b6d082954b6712b5589</td>\n",
       "      <td>106557</td>\n",
       "      <td>z.b. was ist e-fize</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   comment_id                      status_id parent_id  \\\n",
       "0       101180699934084_27535    92886373210_101180699934084        -1   \n",
       "1       101180699934084_28236    92886373210_101180699934084        -1   \n",
       "2  10150099003948783_14797768  92886373210_10150099003948783        -1   \n",
       "\n",
       "   sentence_number                          md5_hash  sentence_id  \\\n",
       "0                0  38540bcfd66b046240b62b9e3482442c        61217   \n",
       "1                1  3fee57e44994d5f406f797e2e9819c13        30919   \n",
       "2                0  58dc5fa1f3b24b6d082954b6712b5589       106557   \n",
       "\n",
       "                                      sentence_text  un  unsure  neut  neg  \\\n",
       "0  ghana und serbien: smiley mit fröhlichem gesicht   1       0     0    0   \n",
       "1                                        wer sonst?   1       0     0    0   \n",
       "2                               z.b. was ist e-fize   0       0     2    0   \n",
       "\n",
       "   pos  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the comment data\n",
    "comments_df = pd.read_csv(FACEBOOK_PATH)\n",
    "# Load the sentiment counts data\n",
    "sentiment_df = pd.read_csv(SENTIMENT_PATH)\n",
    "# Merge the dataframes based on the sentence_id column\n",
    "merged_df = pd.merge(comments_df, sentiment_df, on='sentence_id')\n",
    "merged_df[\"sentence_text\"] = merged_df[\"sentence_text\"].str.lower().replace('[^\\w\\s]','')\n",
    "print(comments_df.shape, sentiment_df.shape)\n",
    "merged_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df[\"sentence_text\"].values\n",
    "y = merged_df[['neut', 'neg', 'pos']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_stop_words = stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=german_stop_words)\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=MultinomialNB(), n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=MultinomialNB(), n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB(), n_jobs=-1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "multi_clf = MultiOutputClassifier(clf, n_jobs=-1)\n",
    "multi_clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['Super, Schön halli hallo'], Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "text = [\"Super, Schön halli hallo\"]\n",
    "new_sentence_counts = vectorizer.transform(text)\n",
    "prediciton = multi_clf.predict(new_sentence_counts)\n",
    "sentiments = np.array(['neutral', 'negative', 'positive'])\n",
    "most_likely_sentiment = sentiments[np.argmax(prediciton)]\n",
    "print(f'Text: {text}, Sentiment: {most_likely_sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: neutral\n",
      "Accuracy: 0.5099009900990099\n",
      "Precision: 0.4426765292808351\n",
      "Recall: 0.5099009900990099\n",
      "F1 Score: 0.4543443236512543\n",
      "Label: negative\n",
      "Accuracy: 0.8960396039603961\n",
      "Precision: 0.8028869718655034\n",
      "Recall: 0.8960396039603961\n",
      "F1 Score: 0.8469094951270585\n",
      "Label: positive\n",
      "Accuracy: 0.7920792079207921\n",
      "Precision: 0.6273894716204294\n",
      "Recall: 0.7920792079207921\n",
      "F1 Score: 0.700180515289098\n"
     ]
    }
   ],
   "source": [
    "# predict the sentiment probabilities for the test set\n",
    "y_pred = multi_clf.predict(X_test_counts)\n",
    "multi_clf.classes_ = ['neutral', 'negative', 'positive']\n",
    "# calculate accuracy, precision, recall, and F1 score for each label\n",
    "for i in range(y_test.shape[1]):\n",
    "    label = multi_clf.classes_[i]\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test[:,i], y_pred[:,i])}\")\n",
    "    print(f\"Precision: {precision_score(y_test[:,i], y_pred[:,i], average='weighted', zero_division=0)}\")\n",
    "    print(f\"Recall: {recall_score(y_test[:,i], y_pred[:,i], average='weighted')}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test[:,i], y_pred[:,i], average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
